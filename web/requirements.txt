# torch==2.0.0
# transformers==4.40.1
# optimum==1.19.1
optimum[onnx, onnxruntime]==1.19.1
fastapi==0.111.0
pytest==8.2.0